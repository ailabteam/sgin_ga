# Geometric-AI for LEO Satellite Link Prediction

This repository contains the official source code, experimental scripts, and results for the paper: **"Geometric-AI: Enhancing LEO Satellite Link Prediction with Deep Learning and Geometric Algebra Features"**, submitted to *IEEE Transactions on Aerospace and Electronic Systems*.

Our research introduces a novel framework that leverages Geometric Algebra (GA) as a powerful feature engineering tool to improve the accuracy and robustness of deep learning models for predicting Inter-Satellite Link (ISL) availability in dynamic LEO satellite constellations.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

![t-SNE Visualization](paper_figures/figure_3_tsne_feature_space.pdf)
*Fig: t-SNE visualization demonstrating the superior class separability of Geometric Algebra features (b) compared to traditional vectors (a).*

## Key Contributions
- **Geometric-AI Framework:** A novel methodology for enhancing AI models with geometrically-aware features.
- **Comprehensive Datasets:** Generation of dynamic network datasets from three real-world LEO constellations (Iridium, Starlink, OneWeb).
- **In-depth Analysis:** Rigorous comparison of MLP and LSTM architectures with Vector, GA, and Hybrid feature sets, including ablation and sensitivity studies.
- **Feature-Architecture Fit:** Novel insights into the synergistic relationship between feature design and model architecture for aerospace applications.

## Repository Structure

The repository is organized to separate reusable code, experimental scripts, and final outputs.

```
.
├── results/                # Stores raw CSV data generated by experiments
├── paper_figures/          # Stores all final, publication-quality figures
├── src/                    # Reusable source code
│   ├── publication_style.py  # Master style definitions for plots
│   └── plot_templates.py     # Functions for generating specific plot types
├── utils.py                # Core utilities: AI models, data prep, training functions
│
├── simulator_v2.py         # 1. Script to generate simulation datasets (*.npz)
├── run_experiments.sh      # 2. Shell script to run multi-seed training experiments
├── analyze_results.py      # 3. Script to analyze multi-seed results (creates Table 3)
├── draw_paper_figures.py   # 4. Main script to generate all paper figures from data
│
├── *.tle                   # TLE files for constellations (e.g., iridium.tle)
└── README.md
```
*Note: Older experimental files (e.g., `ex1...py`, `train_baseline_ai.py`) are kept for historical purposes but are superseded by the main workflow scripts.*

## How to Reproduce Our Results

Follow this streamlined workflow to generate all tables and figures presented in the paper.

### 1. Installation

This project uses `conda` for environment management.

```bash
# 1. Clone the repository
git clone https://github.com/ailabteam/sgin_ga.git
cd sgin_ga

# 2. Create and activate the conda environment
conda create -n sgin_ga python=3.10 -y
conda activate sgin_ga

# 3. Install required packages
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
conda install -c conda-forge numpy pandas matplotlib scikit-learn skyfield clifford seaborn -y
conda install -c conda-forge libstdcxx-ng -y # Required for matplotlib/contourpy on some systems
```

### 2. Stage 1: Data Generation

This stage generates the foundational `.npz` datasets from raw TLE files.

```bash
# 1. Download TLE data
wget -O iridium.tle "https://celestrak.org/NORAD/elements/gp.php?GROUP=iridium&FORMAT=tle"
wget -O starlink.tle "https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle"
wget -O oneweb.tle "https://celestrak.org/NORAD/elements/gp.php?GROUP=oneweb&FORMAT=tle"

# 2. Run the simulator for all three constellations
python simulator_v2.py --group iridium
python simulator_v2.py --group starlink --max_sats 50
python simulator_v2.py --group oneweb --max_sats 50
```

### 3. Stage 2: Running Experiments & Generating Raw Results

This stage runs all the computationally intensive AI training experiments and saves the raw results as `.csv` files in the `results/` directory.

```bash
# 1. Run the main multi-seed experiment (generates data for Table 3)
# This will take a significant amount of time.
chmod +x run_experiments.sh
./run_experiments.sh

# 2. Run supplementary experiments (for figures)
# These scripts will save their output data to the 'results/' directory.
python train_ablation_study.py
python train_sensitivity_analysis.py
python generate_tsne_data.py
python benchmark_operations.py
```
After this stage, the `results/` directory will be populated with all necessary `.csv` files.

### 4. Stage 3: Analysis and Figure Generation

This final stage reads the raw `.csv` results and generates all the publication-quality figures and summary tables.

```bash
# 1. Generate the final summary table (Table 3)
python analyze_results.py

# 2. Generate all figures for the paper
python draw_paper_figures.py
```
All figures will be saved in the `paper_figures/` directory in high-resolution PDF format.

## Citation

If you find this work useful for your research, please consider citing our paper:

```bibtex
@article{Do_GeometricAI_XXXX,
  author    = {Do, Phuc Hao and Van, Nguyen Nang Hung and Pham, Minh Tuan},
  title     = {Geometric-AI: Enhancing LEO Satellite Link Prediction with Deep Learning and Geometric Algebra Features},
  journal   = {IEEE Transactions on Aerospace and Electronic Systems},
  year      = {XXXX},
  volume    = {XX},
  number    = {XX},
  pages     = {XXXX-XXXX},
  doi       = {XX.XXXX/TAES.XXXX.XXXXXXX}
}
```
*(Note: Please update the BibTeX entry with the correct publication details once available.)*

## License

This project is licensed under the MIT License.
